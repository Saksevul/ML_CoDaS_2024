{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaca4266-9799-427a-8af1-5926e663f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabeaf0c-3ef2-4630-aa8e-5aa170dd2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272566c7-a650-4184-bcf6-e306c8c48e26",
   "metadata": {},
   "source": [
    "Sample problem: translate place-value demimals to the Roman numerals (a very simple, exact \"language translation\" task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0dbdf2a-5ea5-4ef3-af3f-a52aac1f3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d250783-25b8-473f-9c44-ab8dc29a38d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are_they_distinct = {roman.toRoman(i + 1) for i in range(3000)}\n",
    "len(are_they_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a72c49-186b-433e-ad5e-29c5387957f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    assert roman.fromRoman(roman.toRoman(i + 1)) == i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e63ef17-f44b-49eb-bc54-6f49b9e98666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([len(roman.toRoman(i + 1)) for i in range(3000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5462c9af-d0ba-4e6b-a268-4e28ffc6fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMDCCCLXXXVIII'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roman.toRoman(2888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd224a7-644a-4bc1-b7c8-e128132a5fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'D', 'I', 'L', 'M', 'V', 'X'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(\"\".join(roman.toRoman(i + 1) for i in range(3000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de6ee06-6d32-47a2-83e8-b952084d61a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    CXXIII    '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{roman.toRoman(123):^14s}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd017c-3d55-41b3-9209-e0132ed543a3",
   "metadata": {},
   "source": [
    "Simple, position-sensitive embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6764df6-9e8a-4387-b302-ca241d07b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_decimal(number: str) -> torch.Tensor:\n",
    "    out = torch.zeros((4, 10))\n",
    "    for i in range(4):\n",
    "        out[i, ord(number[i]) - ord(\"0\")] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b10c020-877c-48d8-b91b-9833954b2b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_decimal(f\"{123:04d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f425bdd-8be4-4320-9ebb-e8d719e44170",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_roman = [\" \", \"I\", \"V\", \"X\", \"L\", \"C\", \"D\", \"M\"]\n",
    "\n",
    "def embed_roman(numeral: str) -> torch.Tensor:\n",
    "    return torch.tensor([lookup_roman.index(numeral[i]) for i in range(14)], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "053f6d62-e2c9-40d5-9fc1-43175528de7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 7, 5, 5, 3, 3, 3, 1, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_roman(f\"{roman.toRoman(1234):^14s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a97edac-ea0a-4224-adc5-ae1dcdb9711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.zeros((3000, 4, 10))\n",
    "for i in range(3000):\n",
    "    inputs[i] = embed_decimal(f\"{i + 1:04d}\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958330fb-a0f9-4b25-ae1e-9c7d464bffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 7,  ..., 1, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.zeros((3000, 14), dtype=torch.int64)\n",
    "for i in range(3000):\n",
    "    targets[i] = embed_roman(f\"{roman.toRoman(i + 1):^14s}\")\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c1fcaac-1629-447e-aee6-e3bcb47f4995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (nn): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=100, out_features=112, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_1, num_hidden_2):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4*10, num_hidden_1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(num_hidden_1, num_hidden_2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(num_hidden_2, 14*8),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.nn(self.flatten(inputs))\n",
    "\n",
    "model = Model(100, 100)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4f5ae06-229b-4d31-baf1-c18a5798caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "loss_functions = [torch.nn.NLLLoss() for _ in range(14)]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f391153e-ae22-4e38-b21e-a749676c3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i + 1 = 100 loss = tensor(39.5999, grad_fn=<AddBackward0>)\n",
      "i + 1 = 200 loss = tensor(38.4044, grad_fn=<AddBackward0>)\n",
      "i + 1 = 300 loss = tensor(39.2050, grad_fn=<AddBackward0>)\n",
      "i + 1 = 400 loss = tensor(37.9730, grad_fn=<AddBackward0>)\n",
      "i + 1 = 500 loss = tensor(37.5135, grad_fn=<AddBackward0>)\n",
      "i + 1 = 600 loss = tensor(37.3955, grad_fn=<AddBackward0>)\n",
      "i + 1 = 700 loss = tensor(37.3782, grad_fn=<AddBackward0>)\n",
      "i + 1 = 800 loss = tensor(37.6053, grad_fn=<AddBackward0>)\n",
      "i + 1 = 900 loss = tensor(37.4700, grad_fn=<AddBackward0>)\n",
      "i + 1 = 1000 loss = tensor(37.2344, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = logsoftmax(model(inputs)).reshape(-1, 14, 8)\n",
    "    loss = sum(f(outputs[:, i, :], targets[:, i]) for i, f in enumerate(loss_functions))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"{i + 1 = } {loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed7e1cf-9d9a-4d0d-a85c-7010b1c1c1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      I       ',\n",
       " '      II      ',\n",
       " '     III      ',\n",
       " '      IV      ',\n",
       " '      V       ',\n",
       " '      VI      ',\n",
       " '     VII      ',\n",
       " '     VIII     ',\n",
       " '      IX      ',\n",
       " '      X       ',\n",
       " '      XI      ',\n",
       " '     XII      ',\n",
       " '     XIII     ',\n",
       " '     XIV      ',\n",
       " '      XV      ',\n",
       " '     XVI      ',\n",
       " '     XVII     ',\n",
       " '    XVIII     ',\n",
       " '     XIX      ',\n",
       " '      XX      ',\n",
       " '     XXI      ',\n",
       " '     XXII     ',\n",
       " '    XXIII     ',\n",
       " '     XXIV     ',\n",
       " '     XXV      ',\n",
       " '     XXVI     ',\n",
       " '    XXVII     ',\n",
       " '    XXVIII    ',\n",
       " '     XXIX     ',\n",
       " '     XXX      ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = torch.nn.Softmax(dim=1)(model(inputs[:30])).reshape(-1, 14, 8).detach().numpy()\n",
    "\n",
    "[\"\".join(x) for x in np.array(lookup_roman)[np.argmax(probabilities, axis=-1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb8444-b821-432b-851e-9c7373fa87ce",
   "metadata": {},
   "source": [
    "It works, but it's not a transformer; it's a (bigger than necessary) feed-forward neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5664084-8bfe-4684-bcb2-7e04f095baf7",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd72a79-1280-4b94-96ec-f037b6bd0749",
   "metadata": {},
   "source": [
    "Now working through [this documentation](https://pytorch.org/tutorials/beginner/translation_transformer.html) (German to English translation).\n",
    "\n",
    "No. That documentation depends on torchtext, which is deprecated (and doesn't work).\n",
    "\n",
    "[This](https://www.kaggle.com/code/nathanyoung1/transformer-based-language-translation-in-pytorch) is promising (doesn't use torchtext) and a thorough explanation of all the pieces, but it shows everything. I'd rather use Torch's built-in [torch.nn.Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) with `nhead=1` so that I don't have to show all of the complexity but I can pull out the attention matrix (and show the one-to-many nature of the learned attention: `'1' → 'I'` (1 char → 1 char), `'8' → 'VIII'` (1 char → 4 char), `'9' → 'IX'` (1 char → 2 char), etc.).\n",
    "\n",
    "It looks to me like even this wouldn't be a _simple_ demo, and if it's not simple, it's not helping with students' understanding. I think I need to give it up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
