{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792f7755-3772-4f6c-8c60-dd69b3e9b90c",
   "metadata": {},
   "source": [
    "# Issues in practice: workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea467bb-cf66-4de4-89f0-3fc9b1011ae1",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5bd8b-7b13-4028-a59e-a46094011a56",
   "metadata": {},
   "source": [
    "## Which library to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcf917-73ea-49c6-8345-494d43621181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.linear_model\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa20758-6492-4dac-9bda-e429cc9d2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_df = pd.read_csv(\"../data/penguins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df70dba-7570-4fa7-97ad-8ae83296c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_prices_df = pd.read_csv(\n",
    "    \"../data/boston-house-prices.csv\", sep=\"\\s+\", header=None,\n",
    "    names=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"],\n",
    ")\n",
    "boston_prices_df = (boston_prices_df - boston_prices_df.mean()) / boston_prices_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4e31e-1177-4d64-977b-559387166247",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b90475-2626-4f2d-86f0-7aa7d116aa1a",
   "metadata": {},
   "source": [
    "## Regression versus classification, loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1f8b6-aa71-44b7-ace2-0ab4947d19c9",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad8e18-8724-441c-aab0-b1cb5f724dce",
   "metadata": {},
   "source": [
    "### Categorical → numerical and numerical → categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960eefe-802e-4266-afe9-bca3c0befc46",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a16c6-9a35-4f26-9b9f-2790771af2a4",
   "metadata": {},
   "source": [
    "### Classification in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec1c8f-cd40-4bdd-ae94-ca52d446a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie_df = penguins_df[penguins_df[\"species\"] == \"Adelie\"][[\"bill_length_mm\", \"bill_depth_mm\"]].dropna()\n",
    "gentoo_df = penguins_df[penguins_df[\"species\"] == \"Gentoo\"][[\"bill_length_mm\", \"bill_depth_mm\"]].dropna()\n",
    "chinstrap_df = penguins_df[penguins_df[\"species\"] == \"Chinstrap\"][[\"bill_length_mm\", \"bill_depth_mm\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941b61d-2890-4f2c-81ba-e20fa131e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = np.concatenate([np.zeros(len(adelie_df)), np.ones(len(gentoo_df))])\n",
    "bill_depth = np.concatenate([adelie_df[\"bill_depth_mm\"].values, gentoo_df[\"bill_depth_mm\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40681572-2458-415d-ace3-5b1c742b4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this user-defined model step centers and scales the input\n",
    "# without this, the optimizer would require many more steps to find the minimum\n",
    "class NormalizeInput(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", torch.tensor([mean], dtype=torch.float32))\n",
    "        self.register_buffer(\"std\", torch.tensor([std], dtype=torch.float32))\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / self.std\n",
    "\n",
    "normalize_input = NormalizeInput(bill_depth.mean(), bill_depth.std())\n",
    "\n",
    "model = nn.Sequential(      # define a 3-step model\n",
    "    normalize_input,        # step 1: center/scale the input\n",
    "    nn.Linear(1, 1),        # step 2: linear transformation (1D → 1D)\n",
    "    nn.Sigmoid(),           # step 3: pass output through a sigmoid\n",
    ")\n",
    "\n",
    "# convert the data into PyTorch Tensors, which are differentiable and can live on a GPU\n",
    "features = torch.tensor(bill_depth[:, np.newaxis], dtype=torch.float32)\n",
    "targets = torch.tensor(species[:, np.newaxis], dtype=torch.float32)\n",
    "\n",
    "# use Binary Cross Entropy as a loss function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# use Adam as an optimizer with a (high) learning rate of 0.03\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.03)\n",
    "\n",
    "# iterate over the same data 1000 times (epochs)\n",
    "for epoch in range(1000):\n",
    "    # tell the optimizer to begin an optimization step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # give the model the input features and ask it to compute its predictions\n",
    "    predictions = model(features)\n",
    "\n",
    "    # compute the loss between these predictions and the intended targets\n",
    "    loss = loss_function(predictions, targets)\n",
    "\n",
    "    # tell the loss function and optimizer to end an optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02020a3d-e654-4aeb-8431-cad485e331be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x = np.linspace(12, 22, 1000)\n",
    "model_y = model(torch.tensor(model_x[:, np.newaxis], dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(bill_depth, species, marker=\"x\")\n",
    "ax.plot(model_x, model_y, color=\"orange\", linewidth=3)\n",
    "\n",
    "ax.set_xlabel(\"Bill depth (mm)\")\n",
    "ax.set_ylabel(\"Probability that species is Gentoo\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf509-9163-4113-9b2d-6e1366297a1b",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8a3d2-84f2-4d1d-8747-4575e5d116c6",
   "metadata": {},
   "source": [
    "### More than two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f239900-ad1c-484d-8a13-bda96c0b609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie_df[\"is_adelie\"] = 1\n",
    "gentoo_df[\"is_gentoo\"] = 1\n",
    "chinstrap_df[\"is_chinstrap\"] = 1\n",
    "\n",
    "onehot_df = pd.concat([adelie_df, gentoo_df, chinstrap_df]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a694fa-38a0-4967-8be9-f710e378b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np = onehot_df[[\"bill_length_mm\", \"bill_depth_mm\"]].values\n",
    "targets_np = onehot_df[[\"is_adelie\", \"is_gentoo\", \"is_chinstrap\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0368e3-1063-48c5-a76c-500595d6ab3c",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b011da-137f-4457-8582-12a94b0db220",
   "metadata": {},
   "source": [
    "### 5-minute exercise: do a logistic regression of 2 features to 3 categories in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206dd90-bac2-46e1-88c3-a4471ccbf89f",
   "metadata": {},
   "source": [
    "Uncomment and run the debugging code if it's helpful to do so.\n",
    "\n",
    "Remember: examine all your variables and look at each step! That's why we're using Python (and Jupyter) in the first place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbab0d-6a02-46d7-9e23-c84647aa647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.tensor(features_np, dtype=torch.float32)\n",
    "targets = torch.tensor(targets_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c554a-ab4a-48c3-909c-292cea7d7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12747e22-f1d1-4de8-bd19-ddc5deff2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61dd34-bc8a-493b-aa90-16fa1926e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeInput(nn.Module):\n",
    "    def __init__(self, mean1, std1, mean2, std2):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", torch.tensor([mean1, mean2], dtype=torch.float32))\n",
    "        self.register_buffer(\"std\", torch.tensor([std1, std2], dtype=torch.float32))\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / self.std\n",
    "\n",
    "normalize_input = NormalizeInput(\n",
    "    features_np[:, 0].mean(), features_np[:, 0].std(),\n",
    "    features_np[:, 1].mean(), features_np[:, 1].std(),\n",
    ")\n",
    "# normalize_input.forward(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c584c7b-587c-46ab-bf12-c33e0f9bb82d",
   "metadata": {},
   "source": [
    "The softmax function is defined as:\n",
    "\n",
    "$$ \\mbox{softmax}_i(x) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} $$\n",
    "\n",
    "Consequentially,\n",
    "\n",
    "$$ \\sum_i \\mbox{softmax}_i(x) = 1 $$\n",
    "\n",
    "When we had only 2 categories, we could focus on only one of them and compute its sigmoid.\n",
    "\n",
    "With 3 categories, we use the softmax to ensure that the model's output probabilities add to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f2072-e6cd-4d25-9e3f-507421be3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_softmax = nn.Sequential(\n",
    "    normalize_input,\n",
    "    nn.Linear(2, 3),\n",
    ")\n",
    "# model_without_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28681b3d-3003-46d3-8406-f3d0b13be14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_without_softmax(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e875008-e1e7-4683-b87c-10a023ec139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_softmax = nn.Sequential(\n",
    "    model_without_softmax,\n",
    "    nn.Softmax(dim=1),\n",
    ")\n",
    "# model_with_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342ac2a-d1f5-48c9-90e3-107519a98736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_with_softmax(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494d438-f518-4d75-acac-2d2bdf9cb438",
   "metadata": {},
   "source": [
    "In the next cell, define a `loss_function`, an `optimizer`, and implement the fit.\n",
    "\n",
    "Use PyTorch's [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), which internally includes the softmax. Don't apply it twice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aeb9e-8f4b-4230-8439-7d681526b229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10220762-f28b-4348-b286-2c6b1f67ed81",
   "metadata": {},
   "source": [
    "The next cell plots the fit, just like Scikit-Learn, using the model with the softmax (because we need to plot probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a2afa-26d4-4ab9-9c37-6fabd665d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# draw three scatter plots, each a different color\n",
    "ax.scatter(features_np[targets_np[:, 0] == 1, 0], features_np[targets_np[:, 0] == 1, 1])\n",
    "ax.scatter(features_np[targets_np[:, 1] == 1, 0], features_np[targets_np[:, 1] == 1, 1])\n",
    "ax.scatter(features_np[targets_np[:, 2] == 1, 0], features_np[targets_np[:, 2] == 1, 1])\n",
    "\n",
    "# compute the three probabilities for every 2D point in the background\n",
    "background_x, background_y = np.meshgrid(np.linspace(29, 62, 100), np.linspace(12, 23, 100))\n",
    "background_2d = np.column_stack([background_x.ravel(), background_y.ravel()])\n",
    "probabilities = model_with_softmax(torch.tensor(background_2d, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "# draw contour lines where the probabilities cross the 50% threshold\n",
    "ax.contour(background_x, background_y, probabilities[:, 0].reshape(background_x.shape), [0.5])\n",
    "ax.contour(background_x, background_y, probabilities[:, 1].reshape(background_x.shape), [0.5])\n",
    "ax.contour(background_x, background_y, probabilities[:, 2].reshape(background_x.shape), [0.5])\n",
    "\n",
    "ax.set_xlabel(\"Bill length (mm)\")\n",
    "ax.set_ylabel(\"Bill depth (mm)\")\n",
    "ax.axis([29, 62, 12, 23])\n",
    "\n",
    "ax.legend([\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8deb6-eae3-478b-b829-9c0caf98afbb",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6353e-b6ec-4b49-88bd-8d8c73e316d6",
   "metadata": {},
   "source": [
    "## Optimizers: learning rate, batches, and epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f91568-c899-456b-87ea-5d131759b461",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd333a-d5cd-48b4-b944-452e9a21c681",
   "metadata": {},
   "source": [
    "### 5-minute exercise: optimize a 2D function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9312b4-3292-4120-860b-cb2a8926b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beale(x, y):\n",
    "    return (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "# a PyTorch \"model\" that just consists of two optimizable parameters\n",
    "class Position2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.xy = nn.Parameter(torch.tensor([-1, 2], dtype=torch.float32, requires_grad=True))\n",
    "    def forward(self):\n",
    "        return self.xy[0], self.xy[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece21ef-16f2-4470-99d0-9ccafb001014",
   "metadata": {},
   "source": [
    "Define a optimizer than can find the true minimum of (3, 0.5), replacing the naive one in this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736bc44-a7a9-4595-8272-4f58e790e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Position2D()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c5536-cd81-43a3-85ac-02d1e1d35ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_start = list(model.parameters())[0].detach().numpy().tolist()\n",
    "\n",
    "path = [path_start]\n",
    "for epoch in range(1000):\n",
    "\n",
    "    # start an optimization step in the usual way\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # this model has no arguments, and its loss function is beale (unusual!)\n",
    "    loss = beale(*model())\n",
    "\n",
    "    # finish an optimization step in the usual way\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # keep track of the path, to plot it\n",
    "    path.append(list(model.parameters())[0].detach().numpy().tolist())\n",
    "\n",
    "path_np = np.array(path)\n",
    "\n",
    "print(\"Final position, should be (3, 0.5):\")\n",
    "print(list(model.parameters())[0])\n",
    "print()\n",
    "print(\"Final loss, should be 0:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fa611-4769-49f1-ad9f-a12f8998141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "background_x, background_y = np.meshgrid(np.linspace(-4.5, 4.5, 1000), np.linspace(-4.5, 4.5, 1000))\n",
    "contours = ax.contour(background_x, background_y, beale(background_x, background_y), [1, 3, 5, 10, 30, 50, 100, 300, 500, 1000], norm=\"log\")\n",
    "ax.clabel(contours, contours.levels)\n",
    "ax.axis([-4.5, 4.5, -4.5, 4.5])\n",
    "\n",
    "ax.scatter([3], [0.5], marker=\"*\", s=1000, c=\"red\")\n",
    "ax.scatter([path_start[0]], [path_start[1]], marker=\"o\", s=300, c=\"red\")\n",
    "ax.plot(path_np[:, 0], path_np[:, 1], c=\"red\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c6294-1368-4bcf-a287-49de2b0371b6",
   "metadata": {},
   "source": [
    "### Batches and epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa433f-4bf7-4f90-8095-7c270d897f4c",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199e2d5-dee4-4ce9-9690-9975c0e26820",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e783429-aefa-4f76-bf73-f56ecb4e5e92",
   "metadata": {},
   "source": [
    "## Feature selection and the \"kernel trick\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321a0c9-5f90-4848-822c-945773c5c44f",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d7d99-ab42-42fe-89e2-bba640b5c5f1",
   "metadata": {},
   "source": [
    "## Under & overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e712a-46ac-4f30-939f-04358f22d194",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83d3cc-a15a-4cfb-815d-4dce1755e2fe",
   "metadata": {},
   "source": [
    "## Parameters versus hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffaae4-74d3-4027-b6b2-eded5ef1b4e6",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607b498-a27f-4a2f-80e8-0459ae2cfbda",
   "metadata": {},
   "source": [
    "## Partitioning data into train-test-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0002d79-f65f-48d0-8319-35dfee8a0909",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716eaed-a743-4521-8e83-9658afce4b4c",
   "metadata": {},
   "source": [
    "## Goodness of fit metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04a3b1-ef8e-4a2c-aaae-7ffb8046c7e5",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b5315-cbfd-446a-9a08-3998e7de4d55",
   "metadata": {},
   "source": [
    "## Regularization: L1, L2, dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
